{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VISt8uPGQMWa"
      },
      "outputs": [],
      "source": [
        "!pip install gradio_client openai huggingface-hub"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install huggingface_hub\n",
        "\n",
        "from huggingface_hub import notebook_login\n",
        "\n",
        "notebook_login()"
      ],
      "metadata": {
        "id": "nQ3HpwFIQQD-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from gradio_client import Client\n",
        "import time\n",
        "import csv\n",
        "\n",
        "def humanize_paraphrases(input_file, output_file):\n",
        "    # Read the CSV file\n",
        "    paraphrases_df = pd.read_csv(input_file)\n",
        "\n",
        "    # Create a client for the Humanizer model\n",
        "    client = Client(\"Farhan1572/humanizer\")\n",
        "\n",
        "    # Open the output CSV file in append mode\n",
        "    with open(output_file, 'w', newline='', encoding='utf-8') as csvfile:\n",
        "        writer = csv.writer(csvfile)\n",
        "        # Write the header\n",
        "        writer.writerow(['original_paraphrase', 'humanized_paraphrase'])\n",
        "\n",
        "        # Process each paraphrase\n",
        "        for index, row in paraphrases_df.iterrows():\n",
        "            paraphrase = row['paraphrase']\n",
        "            try:\n",
        "                # Send the paraphrase to the Humanizer model\n",
        "                result = client.predict(\n",
        "                    AI_text=paraphrase,\n",
        "                    api_name=\"/predict\"\n",
        "                )\n",
        "\n",
        "                # Write the result to the CSV file\n",
        "                writer.writerow([paraphrase, result])\n",
        "\n",
        "                # Flush the file to ensure it's written\n",
        "                csvfile.flush()\n",
        "\n",
        "                # Print progress\n",
        "                print(f\"Processed and saved {index + 1}/{len(paraphrases_df)} paraphrases\")\n",
        "\n",
        "                # Add a small delay to avoid overwhelming the API\n",
        "                time.sleep(1)\n",
        "            except Exception as e:\n",
        "                print(f\"Error processing paraphrase {index + 1}: {str(e)}\")\n",
        "                # Write the original paraphrase if an error occurs\n",
        "                writer.writerow([paraphrase, paraphrase])\n",
        "                csvfile.flush()\n",
        "\n",
        "    print(f\"Humanized paraphrases saved to '{output_file}'\")\n",
        "\n",
        "# Use the function\n",
        "humanize_paraphrases(\"paraphrases_split_4.csv\", \"wiki_paraphrased_human_split_4.csv\")"
      ],
      "metadata": {
        "id": "0jfxoTOyQjYL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}